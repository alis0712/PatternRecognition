# Pattern Recognition
In this course I was exposed to the following topics: 

1. Mathematical foundation (Probability theory, discrete and continous probability, Linear algebra, vector space, matrix theory, optimization, Lagrange optimization)
2. Bayesian decision theory
3. Parameter estimation
4. Non-Parametric techniques of estimating the probability density function (PDF))
6. Support Vector Machine
5. Linear Discriminant Functions
6. Neural Networks for data classification
7. Data clustering and unsupervised classification
8. Hidden Markov Models (HMM)
9. Expectation Maximization (EM)

Feel free to browse some of the work I did for this course in Jupyter Notebook
 
